{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Pipeline: PDF to FAISS Vector Store\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load and chunk a PDF document\n",
    "2. Create embeddings and store them in FAISS\n",
    "3. Save the index locally as .faiss and .pkl files\n",
    "4. Load the saved index and create a retriever for RAG applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries\n",
    "\n",
    "Run this cell first to install all necessary dependencies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration\n",
    "\n",
    "Set your PDF path and output directory here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Path: ../data/dc2523af.pdf\n",
      "Index Save Directory: ../faiss_index\n",
      "Embedding Model: text-embedding-3-large\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "PDF_PATH = \"../data/dc2523af.pdf\"  # Change this to your PDF path\n",
    "INDEX_SAVE_DIR = \"../faiss_index\"  # Directory to save the FAISS index\n",
    "EMBEDDING_MODEL = \"text-embedding-3-large\"  # Embedding model to use\n",
    "\n",
    "# Text splitting parameters\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "\n",
    "print(f\"PDF Path: {PDF_PATH}\")\n",
    "print(f\"Index Save Directory: {INDEX_SAVE_DIR}\")\n",
    "print(f\"Embedding Model: {EMBEDDING_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "model_name = \"gpt-4o\"\n",
    "llm = ChatOpenAI(\n",
    "                model=model_name,\n",
    "                #openai_api_base=openai_api_base\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "Components initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize embeddings\n",
    "print(\"Loading embedding model...\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "print(\"Components initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load and Process PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDF from ../data/dc2523af.pdf...\n",
      "Loaded 69 pages from PDF\n",
      "First page preview (first 200 chars): ...\n"
     ]
    }
   ],
   "source": [
    "# Load PDF\n",
    "print(f\"Loading PDF from {PDF_PATH}...\")\n",
    "loader = PyPDFLoader(PDF_PATH)\n",
    "pages = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(pages)} pages from PDF\")\n",
    "print(f\"First page preview (first 200 chars): {pages[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split Documents into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting documents into chunks...\n",
      "Created 130 chunks\n",
      "First chunk preview:\n",
      "1 Introduction ........................................................................................  5\n",
      "1.1 Ownership of this document 5\n",
      "1.2\t API\tDefinition\tand\tOverview\t 5\n",
      "1.3 Purpose 6\n",
      "1.4 Scope ...\n",
      "Average chunk length: 767 characters\n"
     ]
    }
   ],
   "source": [
    "# Split documents into chunks\n",
    "print(\"Splitting documents into chunks...\")\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks\")\n",
    "print(f\"First chunk preview:\\n{chunks[0].page_content[:200]}...\")\n",
    "print(f\"Average chunk length: {sum(len(chunk.page_content) for chunk in chunks) // len(chunks)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FAISS index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:faiss.loader:Loading faiss.\n",
      "INFO:faiss.loader:Successfully loaded faiss.\n",
      "INFO:faiss:Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created successfully!\n",
      "Index contains 130 vectors\n"
     ]
    }
   ],
   "source": [
    "# Create FAISS vectorstore\n",
    "print(\"Creating FAISS index\")\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "print(\"FAISS index created successfully!\")\n",
    "print(f\"Index contains {vectorstore.index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Index Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving FAISS index to ../faiss_index...\n",
      "Index saved successfully!\n",
      "Files created: ['index.faiss', 'index.pkl']\n"
     ]
    }
   ],
   "source": [
    "# Create directory if it doesn't exist\n",
    "os.makedirs(INDEX_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Save FAISS index locally\n",
    "print(f\"Saving FAISS index to {INDEX_SAVE_DIR}...\")\n",
    "vectorstore.save_local(INDEX_SAVE_DIR)\n",
    "\n",
    "print(\"Index saved successfully!\")\n",
    "\n",
    "# List files in the directory\n",
    "files = os.listdir(INDEX_SAVE_DIR)\n",
    "print(f\"Files created: {files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Load Saved Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS index from ../faiss_index...\n",
      "Index loaded successfully!\n",
      "Loaded index contains 130 vectors\n"
     ]
    }
   ],
   "source": [
    "# Load the saved FAISS index\n",
    "print(f\"Loading FAISS index from {INDEX_SAVE_DIR}...\")\n",
    "loaded_vectorstore = FAISS.load_local(\n",
    "    INDEX_SAVE_DIR, \n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "print(\"Index loaded successfully!\")\n",
    "print(f\"Loaded index contains {loaded_vectorstore.index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create Retriever for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever created successfully!\n",
      "Retriever configured to return top 4 most similar documents\n"
     ]
    }
   ],
   "source": [
    "# Create retriever\n",
    "retriever = loaded_vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4}  # Number of documents to retrieve\n",
    ")\n",
    "\n",
    "print(\"Retriever created successfully!\")\n",
    "print(f\"Retriever configured to return top 4 most similar documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Test the Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing retriever with query: 'What is the main topic of this document?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kh/khjtwkx55nz26qv154hsd08h0000gn/T/ipykernel_12962/3480392225.py:5: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(test_query)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 4 documents\n",
      "\n",
      "==================================================\n",
      "\n",
      "Document 1:\n",
      "Content: contain\tno\texplicit\ttechnology\tor\tprotocol\trestrictions;\trather,\tthe\tdocument\toffers\tbest\tpractices-\n",
      "based\tguidelines\tthat\tensure\tthat\tUAE\tdigital\tgovernment\tAPIs\tare\teffective,\tdesigned\tcorrectly,\t\n",
      "secure\tand\tprovide\tvalue.\n",
      "1.3.\tPurpose...\n",
      "Metadata: {'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 15.0 (Macintosh)', 'creationdate': '2021-04-29T13:43:36+04:00', 'moddate': '2021-05-02T11:10:50+04:00', 'trapped': '/False', 'source': '../data/dc2523af.pdf', 'total_pages': 69, 'page': 7, 'page_label': '7'}\n",
      "------------------------------\n",
      "\n",
      "Document 2:\n",
      "Content: UAE Government API First Guidlines\n",
      "4\n",
      "1.\n",
      "Ownership\n",
      "of this document\n",
      "Introduction\n",
      "1.1....\n",
      "Metadata: {'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 15.0 (Macintosh)', 'creationdate': '2021-04-29T13:43:36+04:00', 'moddate': '2021-05-02T11:10:50+04:00', 'trapped': '/False', 'source': '../data/dc2523af.pdf', 'total_pages': 69, 'page': 4, 'page_label': '4'}\n",
      "------------------------------\n",
      "\n",
      "Document 3:\n",
      "Content: 1.Introduction\n",
      "7\n",
      "The\tpurpose\tof\tthis\tdocument\tis\tto\tprovide\tAPI\tguidelines\tfor\tUAE\tgovernment\tentities.\t\n",
      "The UAE\tgovernment\taims\tto\tadopt\tan\tAPI-first\tapproach\tfor\tthe\tdigital\ttransformation\tinitiatives.\t\n",
      "Government\tentities\tand\tvendors\tcan\tfollow\tthe\tAPI\tguidelines\toutlined\tin\tthis\tdocument\tfor\tgui...\n",
      "Metadata: {'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 15.0 (Macintosh)', 'creationdate': '2021-04-29T13:43:36+04:00', 'moddate': '2021-05-02T11:10:50+04:00', 'trapped': '/False', 'source': '../data/dc2523af.pdf', 'total_pages': 69, 'page': 7, 'page_label': '7'}\n",
      "------------------------------\n",
      "\n",
      "Document 4:\n",
      "Content: Documentation \n",
      "Requirements Description\n",
      "Information Handling, Incident \n",
      "Management and Risk \n",
      "Management\n",
      "Availability, Ownership and \n",
      "Depreciation Policies\n",
      "Governance Frameworks e.g\tPCI\tcompliance\tfor\tPayment\tAPI\n",
      "API Lifecycle Management\n",
      "The\tguidelines\tshould\tdefine\tpolicies\tfor\tAPI\tLifecycle\tmanagem...\n",
      "Metadata: {'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 15.0 (Macintosh)', 'creationdate': '2021-04-29T13:43:36+04:00', 'moddate': '2021-05-02T11:10:50+04:00', 'trapped': '/False', 'source': '../data/dc2523af.pdf', 'total_pages': 69, 'page': 64, 'page_label': '64'}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the retriever with a sample query\n",
    "test_query = \"What is the main topic of this document?\"  # Change this to test with your content\n",
    "\n",
    "print(f\"Testing retriever with query: '{test_query}'\")\n",
    "results = retriever.get_relevant_documents(test_query)\n",
    "\n",
    "print(f\"Retrieved {len(results)} documents\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"Content: {doc.page_content[:300]}...\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Utility Functions for Reusability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions defined!\n"
     ]
    }
   ],
   "source": [
    "def load_or_create_vectorstore(pdf_path: str, index_dir: str, force_recreate: bool = False):\n",
    "    \"\"\"\n",
    "    Load existing vectorstore or create new one if it doesn't exist.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to PDF file\n",
    "        index_dir: Directory for FAISS index\n",
    "        force_recreate: Whether to recreate index even if it exists\n",
    "    \n",
    "    Returns:\n",
    "        FAISS vectorstore object\n",
    "    \"\"\"\n",
    "    if not force_recreate and os.path.exists(index_dir) and os.listdir(index_dir):\n",
    "        print(f\"Loading existing index from {index_dir}\")\n",
    "        return FAISS.load_local(\n",
    "            index_dir, \n",
    "            embeddings, \n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Creating new index from {pdf_path}\")\n",
    "        # Load and process PDF\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        pages = loader.load()\n",
    "        chunks = text_splitter.split_documents(pages)\n",
    "        \n",
    "        # Create and save vectorstore\n",
    "        vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "        os.makedirs(index_dir, exist_ok=True)\n",
    "        vectorstore.save_local(index_dir)\n",
    "        \n",
    "        return vectorstore\n",
    "\n",
    "def create_retriever(pdf_path: str, index_dir: str, k: int = 4, force_recreate: bool = False):\n",
    "    \"\"\"\n",
    "    Create a retriever from PDF.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to PDF file\n",
    "        index_dir: Directory for FAISS index\n",
    "        k: Number of documents to retrieve\n",
    "        force_recreate: Whether to recreate index\n",
    "    \n",
    "    Returns:\n",
    "        LangChain retriever object\n",
    "    \"\"\"\n",
    "    vectorstore = load_or_create_vectorstore(pdf_path, index_dir, force_recreate)\n",
    "    return vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": k}\n",
    "    )\n",
    "\n",
    "print(\"Utility functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Example: Using the Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing index from ../faiss_index\n",
      "Example retriever created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kh/khjtwkx55nz26qv154hsd08h0000gn/T/ipykernel_36565/1846000481.py:14: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results_2 = example_retriever.get_relevant_documents(test_query_2)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Query: 'main concepts'\n",
      "Found 3 relevant documents\n",
      "\n",
      "Doc 1: standards\t supported.\n",
      "8.\tLoosely\tcoupled\tâ€“\tprovide\tflexibility\tand\tminimize\timpact\tof\t\n",
      "changes\tto\toperations\tof\tother\tAPIs.\n",
      "9.\tGranularity\tâ€“\tprovide\tt...\n",
      "\n",
      "Doc 2: early\trather\tthan\ttoo\tlate)\tand\tfrequent\tdelivery\tof\tproducts.\n",
      "â€¢  \n",
      "Configuration\tManagement\t-\tAll\tthe\tcomponents\twhich\tmake\t\n",
      "up\tan\tinstance\tof\tthe\tAPI...\n",
      "\n",
      "Doc 3: UAE Government API First Guidlines\n",
      "14\n",
      "This\tsection\tof\tthe\tdocument\tconsiders\tthe\tbusiness\tand\toperational\t\n",
      "context\t for\t APIs\t within\t the\t UAE\t gover...\n"
     ]
    }
   ],
   "source": [
    "# Example of using utility functions\n",
    "# This will load existing index or create new one if needed\n",
    "example_retriever = create_retriever(\n",
    "    pdf_path=PDF_PATH,\n",
    "    index_dir=INDEX_SAVE_DIR,\n",
    "    k=3,  # Retrieve top 3 documents\n",
    "    force_recreate=False  # Set to True to force recreation\n",
    ")\n",
    "\n",
    "print(\"Example retriever created!\")\n",
    "\n",
    "# Test with a different query\n",
    "test_query_2 = \"main concepts\"  # Change this for your specific content\n",
    "results_2 = example_retriever.get_relevant_documents(test_query_2)\n",
    "\n",
    "print(f\"\\n Query: '{test_query_2}'\")\n",
    "print(f\"Found {len(results_2)} relevant documents\")\n",
    "for i, doc in enumerate(results_2):\n",
    "    print(f\"\\nDoc {i+1}: {doc.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Advanced RAG Chain with Question Rewriting\n",
    "\n",
    "Now let's create a more sophisticated RAG chain that includes:\n",
    "- Question rewriting based on chat history\n",
    "- Context-aware retrieval\n",
    "- Conversational response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional imports loaded!\n"
     ]
    }
   ],
   "source": [
    "# Additional imports for advanced RAG chain\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda, RunnableParallel\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from operator import itemgetter\n",
    "from typing import Dict, Any\n",
    "\n",
    "print(\"Additional imports loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Define Prompts for RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts defined!\n"
     ]
    }
   ],
   "source": [
    "# Contextualize prompt for question rewriting\n",
    "contextualize_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\n",
    "\n",
    "CRITICAL: You MUST respond in {language}. This is mandatory - never use English unless language is \"English\".\n",
    "\"\"\"\n",
    "\n",
    "contextualize_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", contextualize_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# QA prompt for final answer generation\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "CRITICAL INSTRUCTION: You MUST respond in {language}. Do not use English unless language is specifically \"English\". This is mandatory.\n",
    "\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", qa_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "print(\"Prompts defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Create RAG Chain Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdvancedRAGChain class defined!\n"
     ]
    }
   ],
   "source": [
    "class AdvancedRAGChain:\n",
    "    def __init__(self, retriever, llm, contextualize_prompt, qa_prompt):\n",
    "        self.retriever = retriever\n",
    "        self.llm = llm\n",
    "        self.contextualize_prompt = contextualize_prompt\n",
    "        self.qa_prompt = qa_prompt\n",
    "        \n",
    "        # Build the chain\n",
    "        self._build_chain()\n",
    "    \n",
    "    def _format_docs(self, docs):\n",
    "        \"\"\"Format retrieved documents into a single string.\"\"\"\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    def _build_chain(self):\n",
    "        \"\"\"Build the complete RAG chain.\"\"\"\n",
    "        # 1) Question rewriter based on chat history\n",
    "        question_rewriter = (\n",
    "            {\"input\": itemgetter(\"input\"), \"chat_history\": itemgetter(\"chat_history\"), \"language\":itemgetter(\"language\")}\n",
    "            | self.contextualize_prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        \n",
    "        # 2) Retrieve docs for rewritten question\n",
    "        retrieve_docs = question_rewriter | self.retriever | self._format_docs\n",
    "        \n",
    "        # 3) Answer using retrieved context + original input + chat history\n",
    "        self.chain = (\n",
    "            {\n",
    "                \"context\": retrieve_docs,\n",
    "                \"input\": itemgetter(\"input\"),\n",
    "                \"chat_history\": itemgetter(\"chat_history\"),\n",
    "                \"language\":itemgetter(\"language\"),\n",
    "            }\n",
    "            | self.qa_prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "    \n",
    "    def invoke(self, input_dict: Dict[str, Any]) -> str:\n",
    "        \"\"\"Invoke the RAG chain.\"\"\"\n",
    "        return self.chain.invoke(input_dict)\n",
    "    \n",
    "    def stream(self, input_dict: Dict[str, Any]):\n",
    "        \"\"\"Stream the RAG chain response.\"\"\"\n",
    "        return self.chain.stream(input_dict)\n",
    "\n",
    "print(\"AdvancedRAGChain class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Initialize the Advanced RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced RAG Chain initialized!\n"
     ]
    }
   ],
   "source": [
    "# Create the advanced RAG chain using our existing retriever\n",
    "rag_chain = AdvancedRAGChain(\n",
    "    retriever=retriever,\n",
    "    llm=llm,\n",
    "    contextualize_prompt=contextualize_prompt,\n",
    "    qa_prompt=qa_prompt\n",
    ")\n",
    "\n",
    "print(\"Advanced RAG Chain initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\n",
    "    \"input\": \"what principle to follow when create an API?\",  # Ask in French\n",
    "    \"chat_history\": [],\n",
    "    \"language\": \"Arabic\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ø¹Ù†Ø¯ Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª (API)ØŒ ÙŠØ¬Ø¨ Ø§ØªØ¨Ø§Ø¹ Ø¹Ø¯Ø© Ù…Ø¨Ø§Ø¯Ø¦ Ø£Ø³Ø§Ø³ÙŠØ©ØŒ Ù…Ù†Ù‡Ø§: Ø§Ù„Ù‚Ø§Ø¨Ù„ÙŠØ© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù„Ø¶Ù…Ø§Ù† ØªØ¬Ø±Ø¨Ø© Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø©ØŒ Ø§Ù„ØªÙˆØ§ÙÙ‚ÙŠØ© Ù„ØªÙ…ÙƒÙŠÙ† ØªØ¨Ø§Ø¯Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¯ÙˆÙ† ØªØ¨Ø¹ÙŠØ§Øª Ø¹Ù„Ù‰ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©ØŒ ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø± ÙÙŠ Ø§Ù„Ø¬Ù‡ÙˆØ¯. Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø§Ù„Ø§Ø³ØªÙ‚Ù„Ø§Ù„ÙŠØ© Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ Ù…Ø²ÙˆØ¯ÙŠÙ† Ø£Ùˆ ØªÙ‚Ù†ÙŠØ§Øª Ù…Ø¹ÙŠÙ†Ø©ØŒ ÙˆÙ‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„ØªÙˆØ³Ø¹ Ù„ØªÙˆÙÙŠØ± Ø§Ù„Ù…Ø±ÙˆÙ†Ø©ØŒ ÙˆØ§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙ†Ø§Ø³Ù‚ ÙÙŠ Ø§Ù„ØªØºÙŠÙŠØ±Ø§ØªØŒ ÙˆÙƒØ°Ù„Ùƒ Ø§Ù„Ø´ÙØ§ÙÙŠØ© ÙˆØ§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ù…Ø­Ø¯ÙˆØ¯ Ù„ØªÙ‚Ù„ÙŠÙ„ ØªØ£Ø«ÙŠØ± Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø£Ø®Ø±Ù‰.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Test the Advanced RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The main topic of this document is the guidelines and best practices for the effective design, security, and value provision of UAE digital government APIs. It covers various aspects such as API lifecycle management, documentation generation, and business and operational contexts within the UAE government. Additionally, it discusses principles that impact API creation and their broader effects across government entities and public services.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: This document serves as a tool for planning and implementing digital transformation in UAE government entities through the use of APIs. It aims to make government services more interoperable, less dependent on specific vendors or technologies, and easier to update. It provides high-level guidelines for API design and implementation, along with data and information security standards to ensure consistent communication and secure information exchange across government services.\n",
      "\n",
      "==================================================\n",
      "\n",
      "ðŸ” Test 3: Specific question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The key points mentioned include ensuring that government services are interoperable, vendor-agnostic, and future-proof with guidelines for API design that promote a uniform design language. The document emphasizes the importance of consumer-centric design, considering the needs of API consumers and developers, to create intuitive and easy-to-use APIs. It also highlights the significance of data standards and information security standards to maintain secure and consistent data exchange across government services.\n"
     ]
    }
   ],
   "source": [
    "# Test the advanced RAG chain with conversation\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "# Test 1: First question (no chat history)\n",
    "\n",
    "response1 = rag_chain.invoke({\n",
    "    \"input\": \"What is the main topic of this document?\",\n",
    "    \"chat_history\": [],\n",
    "    \"language\":\"French\"\n",
    "})\n",
    "print(f\"Response: {response1}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test 2: Follow-up question with chat history\n",
    "chat_history = [\n",
    "    HumanMessage(content=\"What is the main topic of this document?\"),\n",
    "    AIMessage(content=response1)\n",
    "]\n",
    "\n",
    "response2 = rag_chain.invoke({\n",
    "    \"input\": \"Can you tell me more about it?\",  # This references previous context\n",
    "    \"chat_history\": chat_history,\n",
    "    \"language\":\"French\"\n",
    "})\n",
    "print(f\"Response: {response2}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test 3: New specific question\n",
    "print(\"ðŸ” Test 3: Specific question\")\n",
    "response3 = rag_chain.invoke({\n",
    "    \"input\": \"What are the key points mentioned?\",\n",
    "    \"chat_history\": chat_history,\n",
    "    \"language\":\"French\"\n",
    "})\n",
    "print(f\"Response: {response3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Conversational RAG Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversational RAG helper created!\n"
     ]
    }
   ],
   "source": [
    "class ConversationalRAG:\n",
    "    def __init__(self, rag_chain):\n",
    "        self.rag_chain = rag_chain\n",
    "        self.chat_history = []\n",
    "    \n",
    "    def ask(self, question: str) -> str:\n",
    "        \"\"\"Ask a question and maintain chat history.\"\"\"\n",
    "        response = self.rag_chain.invoke({\n",
    "            \"input\": question,\n",
    "            \"chat_history\": self.chat_history\n",
    "        })\n",
    "        \n",
    "        # Update chat history\n",
    "        self.chat_history.append(HumanMessage(content=question))\n",
    "        self.chat_history.append(AIMessage(content=response))\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear the chat history.\"\"\"\n",
    "        self.chat_history = []\n",
    "        print(\"Chat history cleared!\")\n",
    "    \n",
    "    def get_history(self):\n",
    "        \"\"\"Get the current chat history.\"\"\"\n",
    "        return self.chat_history\n",
    "\n",
    "# Create conversational RAG instance\n",
    "conv_rag = ConversationalRAG(rag_chain)\n",
    "\n",
    "print(\"Conversational RAG helper created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. Interactive Conversation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting interactive conversation...\n",
      "\n",
      "Human: What are the main concepts in this document?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The main concepts in this document are API-first guidelines for UAE government entities, focusing on accelerating digital transformation through best practices in API design and development. It emphasizes the importance of rate limiting, versioning information, and the impact of APIs on government and public services. The document serves as a comprehensive guide to ensure that UAE digital government APIs are effective, innovative, and customer-focused.\n",
      "\n",
      "Human: Can you elaborate on the first concept you mentioned?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The document emphasizes API-first guidelines for UAE government entities as a critical concept, highlighting their role in driving digital transformation. It provides high-level guidelines and low-level best practices to ensure that APIs are seamlessly integrated, interoperable with other platforms, and not tied to specific vendors or technologies. This approach aims to increase the efficiency, interoperability, and future-proofing of government services, while also facilitating real-time processing and flexibility in updating and testing APIs.\n",
      "\n",
      "Human: Are there any examples provided?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The document does not provide specific examples but focuses on overarching concepts and guidelines for designing and implementing APIs within UAE government entities. It outlines the goals and benefits of adopting an API-first strategy, such as enhancing interoperability, reducing vendor lock-in, and ensuring services are more future-proof and easier to update.\n",
      "\n",
      "Conversation history contains 6 messages\n"
     ]
    }
   ],
   "source": [
    "# Example conversation\n",
    "print(\"Starting interactive conversation...\\n\")\n",
    "\n",
    "# Question 1\n",
    "q1 = \"What are the main concepts in this document?\"\n",
    "print(f\"Human: {q1}\")\n",
    "a1 = conv_rag.ask(q1)\n",
    "print(f\"Assistant: {a1}\\n\")\n",
    "\n",
    "# Question 2 (references previous context)\n",
    "q2 = \"Can you elaborate on the first concept you mentioned?\"\n",
    "print(f\"Human: {q2}\")\n",
    "a2 = conv_rag.ask(q2)\n",
    "print(f\"Assistant: {a2}\\n\")\n",
    "\n",
    "# Question 3\n",
    "q3 = \"Are there any examples provided?\"\n",
    "print(f\"Human: {q3}\")\n",
    "a3 = conv_rag.ask(q3)\n",
    "print(f\"Assistant: {a3}\\n\")\n",
    "\n",
    "print(f\"Conversation history contains {len(conv_rag.get_history())} messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What are the main concepts in this document?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The main concepts in this document are API-first guidelines for UAE government entities, focusing on accelerating digital transformation through best practices in API design and development. It emphasizes the importance of rate limiting, versioning information, and the impact of APIs on government and public services. The document serves as a comprehensive guide to ensure that UAE digital government APIs are effective, innovative, and customer-focused.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Can you elaborate on the first concept you mentioned?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The document emphasizes API-first guidelines for UAE government entities as a critical concept, highlighting their role in driving digital transformation. It provides high-level guidelines and low-level best practices to ensure that APIs are seamlessly integrated, interoperable with other platforms, and not tied to specific vendors or technologies. This approach aims to increase the efficiency, interoperability, and future-proofing of government services, while also facilitating real-time processing and flexibility in updating and testing APIs.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Are there any examples provided?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The document does not provide specific examples but focuses on overarching concepts and guidelines for designing and implementing APIs within UAE government entities. It outlines the goals and benefits of adopting an API-first strategy, such as enhancing interoperability, reducing vendor lock-in, and ensuring services are more future-proof and easier to update.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_rag.get_history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey there'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "chain = RunnablePassthrough() | RunnablePassthrough()\n",
    "chain.invoke(\"hey there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HEY THERE'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def str_upper(input):\n",
    "    return input.upper()\n",
    "chain = RunnablePassthrough() | RunnableLambda(str_upper)\n",
    "chain.invoke(\"hey there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22. Summary\n",
    "\n",
    "ðŸŽ‰ **Congratulations!** You have successfully created a complete advanced RAG system with:\n",
    "\n",
    "### Core Features:\n",
    "1. âœ… **PDF Processing**: Loaded and chunked PDF documents\n",
    "2. âœ… **Vector Storage**: Created and saved FAISS index locally\n",
    "3. âœ… **Question Rewriting**: Context-aware question reformulation\n",
    "4. âœ… **Conversational Memory**: Maintains chat history for follow-up questions\n",
    "5. âœ… **Advanced Retrieval**: Retrieves relevant documents based on rewritten questions\n",
    "6. âœ… **Response Generation**: Generates contextual answers using retrieved documents\n",
    "\n",
    "### Key Components:\n",
    "- **Question Rewriter**: Reformulates questions based on chat history\n",
    "- **Document Retriever**: Finds relevant chunks from your PDF\n",
    "- **Response Generator**: Creates answers using retrieved context\n",
    "- **Conversational Interface**: Maintains conversation flow\n",
    "\n",
    "### Files Created:\n",
    "- `index.faiss`: The FAISS index file\n",
    "- `index.pkl`: Metadata and document store\n",
    "\n",
    "### Usage:\n",
    "```python\n",
    "# Simple usage\n",
    "response = rag_chain.invoke({\n",
    "    \"input\": \"Your question here\",\n",
    "    \"chat_history\": []\n",
    "})\n",
    "\n",
    "# Conversational usage\n",
    "conv_rag = ConversationalRAG(rag_chain)\n",
    "answer = conv_rag.ask(\"Your question here\")\n",
    "```\n",
    "\n",
    "### Next Steps:\n",
    "- Replace the demonstration LLM with your preferred model (OpenAI, Claude, etc.)\n",
    "- Customize prompts for your specific use case\n",
    "- Add multiple PDF documents to expand the knowledge base\n",
    "- Implement streaming responses for better user experience\n",
    "- Add evaluation metrics to measure RAG performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
